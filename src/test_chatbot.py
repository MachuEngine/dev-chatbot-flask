import os
import re
import difflib
from flask import Flask, request, jsonify
from openai import OpenAI

# CORS ì„¤ì •
from flask_cors import CORS

# [í•œêµ­ì–´ íŠ¹í™” ë¼ì´ë¸ŒëŸ¬ë¦¬]
from pykospacing import Spacing
from hanspell import spell_checker

# ë¡œê·¸ ì„¤ì •
import logging
import time 


# ----------------------------------------
# 0. ë¡œê¹… ì„¤ì •
# ----------------------------------------
logging.basicConfig(
    level=logging.INFO,  # í•„ìš”í•˜ë©´ DEBUGë¡œ ë³€ê²½
    format="%(asctime)s [%(levelname)s] %(message)s"
)

def _short(text: str, maxlen: int = 80) -> str:
    """ë¡œê·¸ìš©ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì•ë¶€ë¶„ë§Œ ì˜ë¼ì„œ í‘œì‹œ"""
    if not text:
        return ""
    return (text[:maxlen] + "â€¦") if len(text) > maxlen else text

# ----------------------------------------
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ----------------------------------------
# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ê°œë°œìš©)

# [ì¤‘ìš”] ë„ì–´ì“°ê¸° ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ - ì†ë„ ìµœì í™”)
logging.info("Loading Spacing Model... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
spacing = Spacing()
logging.info("Spacing Model Loaded!")


# ----------------------------------------
# 2. í…ìŠ¤íŠ¸ ì²˜ë¦¬ ë° êµì • í•¨ìˆ˜ë“¤
# ----------------------------------------

def preprocess_user_input(text: str) -> str:
    """
    0ë‹¨ê³„: ì „ì²˜ë¦¬ - ë”ë“¬ëŠ” ë§, ë¶ˆí•„ìš”í•œ ë°˜ë³µ ì œê±° (Regex)
    """
    if not text: return text

    logging.debug(f"[preprocess] original: {_short(text)}")
    
    # ë”ë“¬ëŠ” ë§ ì œê±°
    filler_patterns = [r'\bìŒ+\b', r'\bì–´+\b', r'\bê·¸+ê²Œ\b', r'\bë§‰\b']
    for pat in filler_patterns:
        text = re.sub(pat, ' ', text).strip()
    
    # ë°˜ë³µ ë¬¸ì ì¶•ì†Œ (ã…‹ã…‹ã…‹ -> ã…‹ã…‹)
    text = re.sub(r'(ã…‹)\1{2,}', r'\1\1', text)
    text = re.sub(r'(\.)\1{2,}', r'\1\1', text)
    text = re.sub(r'\s+', ' ', text).strip()

    logging.debug(f"[preprocess] processed: {_short(text)}")
    return text


def apply_korean_algorithms(text: str) -> str:
    """
    1ë‹¨ê³„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ë°˜ ê¸°ê³„ì  êµì • (ë„ì–´ì“°ê¸° êµì •)
        - ë§ì¶¤ë²• ê²€ì‚¬ ë¶€ë¶„ì€ ì‚­ì œ
    """
    logging.debug(f"[ko_lib] input: {_short(text)}")
    try:
        # 1. ë„ì–´ì“°ê¸° (Deep Learning)
        text_spaced = spacing(text)
        logging.debug(f"[ko_lib] spaced: {_short(text_spaced)}")
        
        # 2. ë§ì¶¤ë²• (Naver API wrapper) - ì‹¤íŒ¨ ì‹œ ë„ì–´ì“°ê¸° ê²°ê³¼ë§Œ ë°˜í™˜
        # try:
        #    spelled_sent = spell_checker.check(text_spaced)
        #    checked = spelled_sent.checked
        #    logging.debug(f"[ko_lib] spelled: {_short(checked)}")
        #    return checked
        #except Exception as e:
        #    logging.warning(f"[ko_lib] spell_checker error: {e}")
        #    return text_spaced  # ë§ì¶¤ë²• ê²€ì‚¬ ì‹¤íŒ¨ ì‹œ ë„ì–´ì“°ê¸°ë§Œ ì ìš©
        return text_spaced
    except Exception as e:
        logging.error(f"[ko_lib] Korean Lib Error: {e}")
        return text


def generate_diff_feedback(original: str, corrected: str) -> str:
    """
    êµì • í”¼ë“œë°± ìƒì„± (HTML íƒœê·¸ë¡œ ì°¨ì´ì  ê°•ì¡°)
    """
    matcher = difflib.SequenceMatcher(None, original, corrected)
    html_output = []
    
    for opcode, a0, a1, b0, b1 in matcher.get_opcodes():
        if opcode == 'equal':
            html_output.append(original[a0:a1])
        elif opcode == 'insert':  # ì¶”ê°€ëœ ë¶€ë¶„ (ì´ˆë¡)
            html_output.append(
                f"<span style='color:#4caf50; background:#e8f5e9; font-weight:bold;'>{corrected[b0:b1]}</span>"
            )
        elif opcode == 'delete':  # ì‚­ì œëœ ë¶€ë¶„ (ë¹¨ê°• ì·¨ì†Œì„ )
            html_output.append(
                f"<span style='color:#f44336; text-decoration:line-through; opacity:0.7;'>{original[a0:a1]}</span>"
            )
        elif opcode == 'replace':  # ë°”ë€ ë¶€ë¶„
            html_output.append(
                f"<span style='color:#f44336; text-decoration:line-through; opacity:0.7;'>{original[a0:a1]}</span>"
            )
            html_output.append(
                f"<span style='color:#4caf50; background:#e8f5e9; font-weight:bold;'>{corrected[b0:b1]}</span>"
            )
            
    return "".join(html_output)


def get_corrected_text_with_context(user_input: str, history: list, user_level: str = "intermediate"):
    """
    2ë‹¨ê³„: ë¬¸ë§¥(History)ì„ ê³ ë ¤í•œ LLM ìµœì¢… êµì •
    """
    logging.info(f"[correct_with_context] start (level={user_level}, history_len={len(history)})")
    logging.debug(f"[correct_with_context] raw_input: {_short(user_input)}")

    # 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê¸°ë³¸ ì˜¤ë¥˜ ìˆ˜ì •
    base_corrected = apply_korean_algorithms(user_input)
    logging.debug(f"[correct_with_context] base_corrected: {_short(base_corrected)}")
    
    # 2. ëŒ€í™” ê¸°ë¡ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (ìµœê·¼ 6ê°œë§Œ)
    context_str = ""
    if history:
        for msg in history[-6:]:
            role_name = "í•™ìƒ" if msg['role'] == 'user' else "ì„ ìƒë‹˜"
            context_str += f"- {role_name}: {msg['content']}\n"
    else:
        context_str = "(ëŒ€í™” ì‹œì‘)"

    # 3. LLM í”„ë¡¬í”„íŠ¸
    system_prompt = (
    "ë‹¹ì‹ ì€ ì™¸êµ­ì¸ì„ ìœ„í•œ í•œêµ­ì–´ ë¬¸ì¥ êµì • ì „ë‹´ AIì…ë‹ˆë‹¤. "
    "ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ë¬¸ì¥ì„ ë” ì˜ˆì˜ê²Œ ë°”ê¾¸ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, "
    "ëª…ë°±í•œ ì˜¤ë¥˜ë§Œ ìµœì†Œí•œìœ¼ë¡œ ê³ ì¹˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n"
    "### êµì • ì›ì¹™ ###\n"
    "1. ë¬¸ì¥ì´ ì´ë¯¸ ë¬¸ë²•ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì˜ë¯¸ ì „ë‹¬ì— ë¬¸ì œê°€ ì—†ë‹¤ë©´, "
    "ì…ë ¥ëœ ë¬¸ì¥ì„ **í•œ ê¸€ìë„ ë°”ê¾¸ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ë°˜í™˜**í•©ë‹ˆë‹¤.\n"
    "2. ì˜¤íƒ€, ì˜ëª»ëœ ì¡°ì‚¬, ì˜ëª»ëœ í™œìš©, ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ë“± "
    "ê°ê´€ì ì¸ ì˜¤ë¥˜ë§Œ ìˆ˜ì •í•©ë‹ˆë‹¤. ìŠ¤íƒ€ì¼ì„ ë” ê³µì†í•˜ê²Œ/ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¤ê¸° ìœ„í•œ "
    "ë¶ˆí•„ìš”í•œ ë³€ê²½ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
    "3. ì‚¬ìš©ìì˜ ì˜ë¯¸Â·ì •ë³´Â·ë‰˜ì•™ìŠ¤ë¥¼ ì ˆëŒ€ ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤. "
    "ì§ˆë¬¸ì˜ í˜•íƒœ, ë†’ì„ë§/ë°˜ë§, ë§íˆ¬(ì˜ë¬¸í˜•/ëª…ë ¹í˜• ë“±)ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n"
    "   - ì˜ˆ: 'ë‹¹ì‹ ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?'ëŠ” ë¬¸ë²•ì ìœ¼ë¡œ ë¬¸ì œê°€ ì—†ìœ¼ë¯€ë¡œ "
    "ê·¸ëŒ€ë¡œ 'ë‹¹ì‹ ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?'ë¼ê³  ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. "
    "ì´ ë¬¸ì¥ì„ 'ë¬´ì—‡ì„ ë¬¼ì–´ë³´ì‹œê² ì–´ìš”?'ì²˜ëŸ¼ ë°”ê¾¸ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
    "4. ë¬¸ì¥ì„ ë” ê¸¸ê²Œ ì„¤ëª…í•˜ê±°ë‚˜, ì˜ë¯¸ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜, ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì˜ì—­í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. "
    "ì›ë˜ ë¬¸ì¥ì˜ êµ¬ì¡°ì™€ ê¸¸ì´ë¥¼ ìµœëŒ€í•œ ìœ ì§€í•©ë‹ˆë‹¤.\n"
    "5. ìˆ˜ì •ì´ í•„ìš”í•œ ê²½ìš°ì—ë„, ë°”ë€ ê¸€ì ìˆ˜ë¥¼ ìµœì†Œë¡œ ìœ ì§€í•˜ë„ë¡ ë…¸ë ¥í•©ë‹ˆë‹¤. "
    "í•œ ë¬¸ì¥ì„ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ëˆ„ê±°ë‚˜, ì—¬ëŸ¬ ë¬¸ì¥ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë“±ì˜ í° êµ¬ì¡° ë³€ê²½ì€ "
    "ì •ë§ í•„ìš”í•  ë•Œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
    "6. ì‚¬ìš©ìì˜ í•œêµ­ì–´ ì‹¤ë ¥ ìˆ˜ì¤€(user_level)ì€ **í‘œí˜„ ë‚œì´ë„ ì¡°ì ˆ**ì—ë§Œ ì‚¬ìš©í•˜ê³ , "
    "ë¬¸ì¥ì˜ ì˜ë¯¸ì™€ ë§íˆ¬ëŠ” ë°”ê¾¸ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
    "7. ê³ ìœ ëª…ì‚¬, ìˆ«ì, ì „ë¬¸ ìš©ì–´, ì˜ë„ì ì¸ ë°˜ë³µ/ê°•ì¡° ë“±ì€ ë¬¸ì œê°€ ì—†ëŠ” í•œ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.\n"
    "8. ë¶€ì—° ì„¤ëª…, ë¶„ì„, ì´ìœ  ì„¤ëª… ë“±ì„ ì¶œë ¥í•˜ì§€ ë§ê³ , "
    "êµì •ëœ ë¬¸ì¥ í…ìŠ¤íŠ¸ë§Œ í•œ ë²ˆ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
)

    
    user_prompt = (
        f"### ëŒ€í™” íë¦„ ###\n{context_str}\n\n"
        f"### í˜„ì¬ ë¬¸ì¥ (ê¸°ì´ˆ êµì •ë¨) ###\n{base_corrected}\n\n"
        "### êµì • ê²°ê³¼ ###"
    )

    try:
        t0 = time.time()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1
        )
        dt = time.time() - t0

        final_correction = response.choices[0].message.content.strip()
        logging.info(f"[correct_with_context] LLM success (elapsed={dt:.2f}s)")
        logging.debug(f"[correct_with_context] final_correction: {_short(final_correction)}")

        # í† í° ì‚¬ìš©ëŸ‰ ìˆìœ¼ë©´ ê°™ì´ ë¡œê·¸
        usage = getattr(response, "usage", None)
        if usage:
            logging.info(
                f"[correct_with_context] token usage input={usage.prompt_tokens}, "
                f"output={usage.completion_tokens}, total={usage.total_tokens}"
            )
    except Exception as e:
        print(f"LLM Error: {e}")
        final_correction = base_corrected # ì—ëŸ¬ ì‹œ ê¸°ê³„ì  êµì •ë³¸ ì‚¬ìš©

    # 4. Diff ìƒì„±
    diff_html = generate_diff_feedback(user_input, final_correction)
    
    return final_correction, diff_html


# ----------------------------------------
# 3. RAG (ê²€ìƒ‰) ë° ì‘ë‹µ ìƒì„±
# ----------------------------------------

# ë³„ë„ DBë¡œ ëŒ€ì²´ í•„ìš”
KNOWLEDGE_BASE = {
    # ...
    "í•™ìŠµ ë‹¨ê³„ ì •ë³´": "í•™ìŠµ ë‹¨ê³„ ì •ë³´ëŠ” í™ˆí˜ì´ì§€ ë©”ë‰´ì˜ [ìê¸° í•™ìŠµ ì •ë³´ ë³´ê¸°]ë©”ë‰´ë¡œ ë“¤ì–´ê°€ë©´ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "ë‹¤ìŒ í•™ìŠµ ë‹¨ê³„": "ë‹¤ìŒ ë‹¨ê³„ í•™ìŠµì€ í˜„ì¬ ë‹¨ê³„ë¥¼ ì™„ë£Œí•´ì•¼ë§Œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    # ...
}

def retrieve_context(query: str) -> str:
    logging.debug(f"[RAG] retrieve_context query: {_short(query)}")
    context = []
    hit_keys = []
    for k, v in KNOWLEDGE_BASE.items():
        if k in query:
            context.append(v)
            hit_keys.append(k)

    if context:
        logging.info(f"[RAG] hit keys: {hit_keys}")
    else:
        logging.info("[RAG] no related knowledge found")

    return "\n".join(context) if context else "ê´€ë ¨ ì§€ì‹ ì—†ìŒ"

def get_chatbot_response_with_rag(corrected_text: str, history: list) -> tuple:
    """
    # 1. RAGë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê³ 
    # 2.  user_input : ì´ë²ˆ í„´(êµì •ëœ) ì‚¬ìš©ì ë°œí™”
        chat_history : ì´ì „ í„´ ëŒ€í™” ë‚´ì—­ (role/user, assistant êµ¬ì¡°)
    """
    logging.info("[chatbot] generating response with RAG")
    logging.debug(f"[chatbot] corrected_text: {_short(corrected_text)}")

    retrieved_context = retrieve_context(corrected_text)
    logging.debug(f"[chatbot] retrieved_context: {_short(retrieved_context)}")

    system_msg = (
        "ë‹¹ì‹ ì˜ ì´ë¦„ì€ ë¬´ê¶í™”ì…ë‹ˆë‹¤.\n"
        "ë‹¹ì‹ ì€ ì¹œì ˆí•œ í•œêµ­ì–´ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ë§ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.\n"
        "í•„ìš”í•˜ë‹¤ë©´ ì•„ë˜ ì§€ì‹ì„ ì°¸ê³ í•´ì„œ ì„¤ëª…ì´ë‚˜ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.\n"
        f"ì°¸ê³  ì§€ì‹: {retrieved_context}"
    )

    try:
        t0 = time.time()
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": corrected_text}
            ],
            temperature=0.1
        )
        dt = time.time() - t0
        logging.info(f"[chatbot] response LLM success (elapsed={dt:.2f}s)")

        usage = getattr(response, "usage", None)
        if usage:
            logging.info(
                f"[chatbot] token usage input={usage.prompt_tokens}, "
                f"output={usage.completion_tokens}, total={usage.total_tokens}"
            )

        return response.choices[0].message.content.strip(), retrieved_context
    except Exception as e:
        logging.error(f"[chatbot] LLM Error: {e}")
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}", ""


# ----------------------------------------
# 4. API ë¼ìš°íŠ¸ (ì„œë²„ í†µì‹ )
# ----------------------------------------

@app.route('/chat', methods=['POST'])
def chat():
    t_start = time.time()

    data = request.get_json()
    user_input = data.get('message')
    chat_history = data.get('history', [])  # [í•µì‹¬] ëŒ€í™” ê¸°ë¡ ë°›ê¸°
    user_level = data.get('level', 'intermediate')

    if not user_input:
        logging.warning("[/chat] empty message received")
        return jsonify({"error": "No message"}), 400
    
    logging.info(
        f"[/chat] request "
        f"level={user_level}, history_len={len(chat_history)}, input_len={len(user_input)}"
    )
    logging.debug(f"[/chat] raw_input: {_short(user_input)}")

    # 1. ì „ì²˜ë¦¬
    t0 = time.time()
    preprocessed = preprocess_user_input(user_input)
    t1 = time.time()
    logging.info(f"[/chat] preprocess done (elapsed={t1 - t0:.3f}s)")

    # 2. êµì • (ë¼ì´ë¸ŒëŸ¬ë¦¬ + LLM + ë¬¸ë§¥ë°˜ì˜)
    corrected, diff_html = get_corrected_text_with_context(preprocessed, chat_history, user_level)
    t2 = time.time()
    logging.info(f"[/chat] correction done (elapsed={t2 - t1:.3f}s)")
    logging.debug(f"[/chat] corrected_input: {_short(corrected)}")

    # 3. ì±—ë´‡ ì‘ë‹µ ìƒì„±
    bot_response, rag_info = get_chatbot_response_with_rag(corrected, chat_history)
    t3 = time.time()
    logging.info(f"[/chat] response generation done (elapsed={t3 - t2:.3f}s)")
    logging.debug(f"[/chat] bot_response: {_short(bot_response)}")

    total = t3 - t_start
    logging.info(f"[/chat] total elapsed={total:.3f}s")

    return jsonify({
        "original_input": user_input,
        "corrected_input": corrected,
        "diff_html": diff_html,        # í™”ë©´ì— ë³´ì—¬ì¤„ êµì • í”¼ë“œë°±
        "chatbot_response": bot_response,
        "retrieved_context": rag_info
    })


@app.route('/', methods=['GET'])
def index():
    return """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>í•œêµ­ì–´ AI íŠœí„°</title>
    <style>
        body { margin:0; padding:0; background:#121212; color:#eee; font-family:'Malgun Gothic', sans-serif; display:flex; justify-content:center; align-items:center; height:100vh; }
        .container { width:1000px; height:650px; display:grid; grid-template-columns: 1fr 350px; gap:20px; }
        
        /* ì™¼ìª½ ì±„íŒ…ì°½ */
        .chat-panel { background:#1e1e1e; border-radius:15px; display:flex; flex-direction:column; padding:20px; }
        #chatbox { flex:1; overflow-y:auto; margin-bottom:15px; padding-right:10px; }
        .msg { padding:10px 15px; border-radius:10px; margin-bottom:10px; max-width:80%; line-height:1.4; }
        .user { background:#ffd700; color:#000; align-self:flex-end; margin-left:auto; }
        .bot { background:#333; color:#fff; align-self:flex-start; }
        
        .input-area { display:flex; gap:10px; }
        input { flex:1; padding:12px; border-radius:8px; border:none; background:#333; color:white; outline:none; }
        button { padding:12px 20px; background:#ffd700; border:none; border-radius:8px; font-weight:bold; cursor:pointer; }
        button:hover { background:#e6c200; }

        /* ì˜¤ë¥¸ìª½ ë¶„ì„ì°½ */
        .info-panel { background:#1e1e1e; border-radius:15px; padding:20px; display:flex; flex-direction:column; }
        .info-title { font-size:18px; font-weight:bold; color:#ffd700; margin-bottom:15px; text-align:center; }
        #debugBox { flex:1; overflow-y:auto; font-size:14px; color:#ccc; }
        .debug-item { background:#2a2a2a; padding:10px; margin-bottom:10px; border-radius:8px; }
        .debug-label { font-weight:bold; color:#fff; margin-bottom:5px; display:block; }
    </style>
</head>
<body>
    <div class="container">
        <div class="chat-panel">
            <div id="chatbox">
                <div class="msg bot">ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?</div>
            </div>
            <div class="input-area">
                <input type="text" id="message" placeholder="í•œêµ­ì–´ë¡œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”..." />
                <button id="submitBtn">ì „ì†¡</button>
            </div>
        </div>

        <div class="info-panel">
            <div class="info-title">ì‹¤ì‹œê°„ AI ë¶„ì„</div>
            <div id="debugBox">
                <div class="debug-item">ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë©´ ì´ê³³ì— êµì • ë‚´ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤.</div>
            </div>
        </div>
    </div>

<script>
    const chatbox = document.getElementById('chatbox');
    const debugBox = document.getElementById('debugBox');
    const msgInput = document.getElementById('message');
    const submitBtn = document.getElementById('submitBtn');

    // [í•µì‹¬] ëŒ€í™” ë¬¸ë§¥(History) ì €ì¥ìš© ë°°ì—´
    let chatHistory = [];

    function addMsg(text, type) {
        const div = document.createElement('div');
        div.classList.add('msg', type);
        div.textContent = text;
        chatbox.appendChild(div);
        chatbox.scrollTop = chatbox.scrollHeight;
    }

    function addDebug(label, htmlContent) {
        const div = document.createElement('div');
        div.classList.add('debug-item');
        div.innerHTML = `<span class="debug-label">${label}</span>${htmlContent}`;
        debugBox.appendChild(div);
        debugBox.scrollTop = debugBox.scrollHeight;
    }

    submitBtn.onclick = function() {
        const text = msgInput.value.trim();
        if(!text) return;

        // 1. ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        addMsg(text, 'user');
        msgInput.value = '';

        // 2. ì„œë²„ ì „ì†¡ (ë©”ì‹œì§€ + íˆìŠ¤í† ë¦¬)
        fetch('/chat', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                message: text,
                history: chatHistory,  // ë¬¸ë§¥ ì „ì†¡
                level: "intermediate"
            })
        })
        .then(res => res.json())
        .then(data => {
            // 3. ë¶„ì„ ê²°ê³¼ í‘œì‹œ (ì´ˆê¸°í™” í›„ í‘œì‹œ)
            debugBox.innerHTML = "";
            addDebug("ğŸ“ ì›ë˜ ë¬¸ì¥", data.original_input);
            addDebug("ğŸ“ êµì • í”¼ë“œë°±", data.diff_html);
            addDebug("ğŸ§  RAG ì§€ì‹", data.retrieved_context);

            // 4. ì±—ë´‡ ì‘ë‹µ í‘œì‹œ
            addMsg(data.chatbot_response, 'bot');

            // 5. íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (êµì •ëœ ë¬¸ì¥ + ì±—ë´‡ ì‘ë‹µ)
            chatHistory.push({ "role": "user", "content": data.corrected_input });
            chatHistory.push({ "role": "assistant", "content": data.chatbot_response });
        })
        .catch(err => {
            console.error(err);
            addMsg("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", 'bot');
        });
    };

    // ì—”í„°í‚¤ ì…ë ¥ ì§€ì›
    msgInput.addEventListener("keypress", (e) => {
        if(e.key === "Enter") submitBtn.click();
    });
</script>
</body>
</html>
    """

if __name__ == '__main__':
    print("=== í•œêµ­ì–´ êµìœ¡ AI ì±—ë´‡ ì„œë²„ ì‹œì‘ (http://127.0.0.1:5000) ===")
    app.run(debug=True)